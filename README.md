**Выполнил студент группы М8О-401Б-21 Меджидли Исмаил**


В файле [Лабы.ipynb](https://github.com/imedzhidli/Multimedia/blob/main/Лабы.ipynb) находятся выполненные лабораторные работы №1-5 по курсу "Методы, средства и технологии мультимедиа".

## Вывод по лабораторным работам №1-5

Результаты, полученные алгоритмами, представлены в таблицах ниже.

**Задача классификации:**
| Алгоритм            | Задача        | Метрика   |   Бейзлайн |   Улучшенный бейзлайн |   Самостоятельная имплементация алгоритма |
|:--------------------|:--------------|:----------|-----------:|----------------------:|------------------------------------------:|
| KNN                 | классификация | Accuracy  |   0.773333 |              0.813333 |                                  0.8      |
| Линейные модели     | классификация | Accuracy  |   0.6      |              0.613333 |                                  0.28     |
| Решающее дерево     | классификация | Accuracy  |   0.773333 |              0.786667 |                                  0.813333 |
| Случайный лес       | классификация | Accuracy  |   0.773333 |              0.813333 |                                  0.786667 |
| Градиентный бустинг | классификация | Accuracy  |   0.8      |              0.786667 |                                  0.786667 |


**Задача регресcии:**
| Алгоритм            | Задача    | Метрика   |   Бейзлайн |   Улучшенный бейзлайн |   Самостоятельная имплементация алгоритма |
|:--------------------|:----------|:----------|-----------:|----------------------:|------------------------------------------:|
| KNN                 | регрессия | MAE       |    52.9378 |               43.2178 |                                   43.1111 |
| Линейные модели     | регрессия | MAE       |   105.287  |              101.81   |                                  317.653  |
| Решающее дерево     | регрессия | MAE       |    30.9733 |               26.1592 |                                   30.9726 |
| Случайный лес       | регрессия | MAE       |    42.9662 |               34.5365 |                                   32.4897 |
| Градиентный бустинг | регрессия | MAE       |    47.2004 |               41.474  |                                   38.8758 |

Определим алгоритмы, которые показали наилучшие результаты для обоих типов задач в каждом из случаев.

**Задача классификации:**

*   Бейзлайн: все алгоритмы равны, только линейная модель имеет меньший показатель
*   Улучшенный бейзлайн: KNN, случайный лес
*   Самостоятельная имплементация: решающее дерево

**Задача регресcии:**

*   Бейзлайн: решающее дерево
*   Улучшенный бейзлайн: решающее дерево
*   Самостоятельная имплементация: решающее дерево


В общем, линейные модели демонстрируют наименьшие показатели, тогда как алгоритм решающего дерева показывает наилучшие результаты. Это может быть обусловлено тем, что связь между признаками и целевой переменной является нелинейной или сложной, в то время как линейные модели требуют линейной (или логистической в случае классификации) зависимости для эффективного обучения. Линейные модели также более подвержены влиянию шума в данных, в то время как решающее дерево может быть более устойчивым к определённым видам шума, так как оно принимает решения на основе значимых порогов. Если рассматривать более сложные модели, такие как случайный лес или градиентный бустинг, которые основаны на алгоритме решающего дерева, то они могут показывать менее удовлетворительные результаты по сравнению с одним деревом при небольших размерах датасета из-за своей сложности и склонности к переобучению.